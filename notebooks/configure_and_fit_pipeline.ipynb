{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import configparser\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_and_fit_pipeline():\n",
    "\n",
    "    warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
    "    warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "\n",
    "    # Ruta del proyecto\n",
    "    project_path = os.path.dirname(os.getcwd())  # Subir un nivel al directorio padre\n",
    "\n",
    "    data_path = os.path.join(project_path, \"data\", \"raw\", \"loan_data.csv\")\n",
    "    data = pd.read_csv(data_path)\n",
    "\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(os.path.join(project_path, \"pipeline.cfg\"))\n",
    "\n",
    "    # Variable objetivo\n",
    "    target_var = config.get('GENERAL', 'TARGET')\n",
    "\n",
    "    # Verificar que la variable objetivo esté presente\n",
    "    if target_var not in data.columns:\n",
    "        raise ValueError(f\"La variable objetivo '{target_var}' no está presente en los datos.\")\n",
    "\n",
    "    X = data.drop(columns=[target_var])\n",
    "    y = data[target_var]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Cargar pipeline base\n",
    "    artifacts_path = os.path.join(project_path, 'artifacts')\n",
    "    pipeline_path = os.path.join(artifacts_path, 'pipeline.pkl')\n",
    "\n",
    "    if not os.path.exists(pipeline_path):\n",
    "        raise FileNotFoundError(f\"No se encontró el archivo del pipeline en '{pipeline_path}'.\")\n",
    "\n",
    "    with open(pipeline_path, 'rb') as f:\n",
    "        base_pipeline = pickle.load(f)\n",
    "\n",
    "    # Modelos\n",
    "    models = {\n",
    "        'LogisticRegression': LogisticRegression(max_iter=500, random_state=42),\n",
    "        'RandomForestClassifier': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        'DecisionTreeClassifier': DecisionTreeClassifier(random_state=42),\n",
    "        'AdaBoostClassifier': AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "        'XGBClassifier': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "    }\n",
    "\n",
    "    # Configurar MLflow\n",
    "    mlflow.set_experiment(\"Loan Default Prediction\")\n",
    "    best_model = None\n",
    "    best_score = -float('inf')\n",
    "    metric = accuracy_score\n",
    "\n",
    "    print(\"Evaluando modelos...\")\n",
    "    for model_name, model in models.items():\n",
    "        with mlflow.start_run(run_name=model_name):\n",
    "            # Crear un pipeline temporal con el modelo\n",
    "            temp_pipeline = Pipeline(steps=[\n",
    "                ('preprocessing', base_pipeline),\n",
    "                ('classifier', model)\n",
    "            ])\n",
    "\n",
    "            # Validación cruzada\n",
    "            scores = cross_val_score(temp_pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "            avg_score = scores.mean()\n",
    "\n",
    "            print(f\"{model_name}: {avg_score:.4f}\")\n",
    "\n",
    "            # Registrar parámetros y métricas en MLflow\n",
    "            mlflow.log_param(\"model_name\", model_name)\n",
    "            mlflow.log_metric(\"cv_accuracy\", avg_score)\n",
    "\n",
    "            # Actualizar el mejor modelo si supera al actual\n",
    "            if avg_score > best_score:\n",
    "                best_model = model\n",
    "                best_score = avg_score\n",
    "\n",
    "    print(f\"Mejor modelo: {best_model.__class__.__name__} con puntuación: {best_score:.4f}\")\n",
    "\n",
    "    # Crear el pipeline final con el mejor modelo\n",
    "    final_pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', base_pipeline),\n",
    "        ('classifier', best_model)\n",
    "    ])\n",
    "\n",
    "    # Ajustar el pipeline final a los datos de entrenamiento\n",
    "    final_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluar el pipeline en el conjunto de prueba\n",
    "    y_pred = final_pipeline.predict(X_test)\n",
    "    test_score = metric(y_test, y_pred)\n",
    "    print(f\"Puntuación en el conjunto de prueba: {test_score:.4f}\")\n",
    "\n",
    "    # Registrar el pipeline final en MLflow\n",
    "    with mlflow.start_run(run_name=\"Final Pipeline\") as run:\n",
    "        mlflow.log_metric(\"test_accuracy\", test_score)\n",
    "\n",
    "        # Guardar el modelo en MLflow\n",
    "        mlflow.sklearn.log_model(final_pipeline, \"model\")\n",
    "\n",
    "        # Guardar el pipeline ajustado como artefacto local\n",
    "        fitted_pipeline_path = os.path.join(artifacts_path, 'fitted_pipeline.pkl')\n",
    "        with open(fitted_pipeline_path, 'wb') as f:\n",
    "            pickle.dump(final_pipeline, f)\n",
    "\n",
    "        mlflow.log_artifact(fitted_pipeline_path, artifact_path=\"artifacts\")\n",
    "        print(f\"Pipeline final ajustado y guardado en: {fitted_pipeline_path}\")\n",
    "    \n",
    "    mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configure_and_fit_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = mlflow.search_experiments()\n",
    "print(experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-miniproyecto2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
